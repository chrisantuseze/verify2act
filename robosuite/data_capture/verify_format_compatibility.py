"""
Format Compatibility Verification Script

Tests that data generated by robosuite's episode_recorder matches
the format expected by Points2Plans dataloader.
"""

import numpy as np
import pickle
import sys
from pathlib import Path

def verify_block_naming(data_dict, attrs_dict, num_objects):
    """Verify block naming convention matches dataloader expectations."""
    print(f"\nðŸ” Checking block naming for {num_objects} objects...")
    
    issues = []
    
    # Check data['objects'] keys
    for obj_idx in range(num_objects):
        if num_objects >= 10 and obj_idx + 1 < 10:
            expected_name = f"block_0{obj_idx + 1}"
        else:
            expected_name = f"block_{obj_idx + 1}"
        
        if expected_name not in data_dict['objects']:
            issues.append(f"  âŒ Missing data['objects']['{expected_name}']")
        
        if expected_name not in attrs_dict['objects']:
            issues.append(f"  âŒ Missing attrs['objects']['{expected_name}']")
    
    if issues:
        for issue in issues:
            print(issue)
        return False
    else:
        print("  âœ… All block names correct")
        return True

def verify_point_clouds(data_dict, num_objects):
    """Verify point cloud array naming and shapes."""
    print(f"\nðŸ” Checking point cloud arrays...")
    
    issues = []
    
    for obj_idx in range(num_objects):
        base_key = f"point_cloud_{obj_idx + 1}"
        
        for suffix in ['', 'sampling', 'sampling_noise']:
            key = base_key + suffix if suffix else base_key
            
            if key not in data_dict:
                issues.append(f"  âŒ Missing {key}")
            else:
                arr = data_dict[key]
                if not isinstance(arr, np.ndarray):
                    issues.append(f"  âŒ {key} is not numpy array")
                elif arr.ndim != 3:
                    issues.append(f"  âŒ {key} has wrong dims: {arr.shape}")
                elif arr.shape[1] != 128 or arr.shape[2] != 3:
                    issues.append(f"  âš ï¸  {key} shape {arr.shape} (expected (T, 128, 3))")
    
    if issues:
        for issue in issues:
            print(issue)
        return False
    else:
        print("  âœ… All point cloud arrays correct")
        return True

def verify_contact_format(data_dict):
    """Verify contact list format."""
    print(f"\nðŸ” Checking contact format...")
    
    if 'contact' not in data_dict:
        print("  âŒ Missing data['contact']")
        return False
    
    contacts = data_dict['contact']
    if len(contacts) == 0:
        print("  âš ï¸  No contacts recorded (may be normal)")
        return True
    
    # Check first timestep with contacts
    for timestep_contacts in contacts:
        if len(timestep_contacts) > 0:
            contact = timestep_contacts[0]
            if 'body0' not in contact or 'body1' not in contact:
                print("  âŒ Contact missing 'body0' or 'body1'")
                return False
            if not isinstance(contact['body0'], (int, np.integer)):
                print(f"  âŒ body0 is not int: {type(contact['body0'])}")
                return False
            break
    
    print("  âœ… Contact format correct")
    return True

def verify_action_list(attrs_dict):
    """Verify action list format."""
    print(f"\nðŸ” Checking action list...")
    
    if 'sudo_action_list' not in attrs_dict:
        print("  âŒ Missing attrs['sudo_action_list']")
        return False
    
    action_list = attrs_dict['sudo_action_list']
    if len(action_list) == 0:
        print("  âš ï¸  Empty action list")
        return True
    
    for idx, action in enumerate(action_list):
        if not isinstance(action, list) or len(action) != 3:
            print(f"  âŒ Action {idx} wrong format: {action}")
            return False
        
        skill, obj_id, params = action
        
        # Check skill mapping
        if skill not in ['pickplace', 'push']:
            print(f"  âš ï¸  Action {idx} unexpected skill: {skill}")
        
        # Check object ID is string
        if not isinstance(obj_id, str):
            print(f"  âŒ Action {idx} obj_id not string: {type(obj_id)}")
            return False
        
        # Check continuous params
        if not isinstance(params, list) or len(params) != 3:
            print(f"  âŒ Action {idx} params wrong: {params}")
            return False
    
    print(f"  âœ… Action list correct ({len(action_list)} actions)")
    return True

def verify_metadata(attrs_dict):
    """Verify object metadata structure."""
    print(f"\nðŸ” Checking metadata...")
    
    issues = []
    
    for block_name, obj_attrs in attrs_dict['objects'].items():
        if 'extents' not in obj_attrs:
            issues.append(f"  âŒ {block_name} missing 'extents'")
        if 'extents_ranges' not in obj_attrs:
            issues.append(f"  âŒ {block_name} missing 'extents_ranges'")
        if 'fix_base_link' not in obj_attrs:
            issues.append(f"  âŒ {block_name} missing 'fix_base_link'")
    
    if issues:
        for issue in issues:
            print(issue)
        return False
    else:
        print("  âœ… Metadata structure correct")
        return True

def verify_episode_file(filepath):
    """Run all verification checks on an episode file."""
    print(f"\n{'='*60}")
    print(f"ðŸ“ Verifying: {filepath}")
    print(f"{'='*60}")
    
    try:
        with open(filepath, 'rb') as f:
            data_dict, attrs_dict = pickle.load(f)
    except Exception as e:
        print(f"âŒ Failed to load file: {e}")
        return False
    
    # Determine number of objects
    num_objects = len([k for k in data_dict['objects'].keys() if 'block' in k])
    print(f"\nðŸ“Š Episode Info:")
    print(f"  Objects: {num_objects}")
    print(f"  Timesteps: {data_dict['point_cloud_1'].shape[0] if 'point_cloud_1' in data_dict else 'unknown'}")
    
    # Run all checks
    all_passed = True
    all_passed &= verify_block_naming(data_dict, attrs_dict, num_objects)
    all_passed &= verify_point_clouds(data_dict, num_objects)
    all_passed &= verify_contact_format(data_dict)
    all_passed &= verify_action_list(attrs_dict)
    all_passed &= verify_metadata(attrs_dict)
    
    print(f"\n{'='*60}")
    if all_passed:
        print("âœ… ALL CHECKS PASSED - Format is compatible!")
    else:
        print("âŒ SOME CHECKS FAILED - Format needs fixes")
    print(f"{'='*60}\n")
    
    return all_passed

if __name__ == "__main__":
    if len(sys.argv) > 1:
        # Verify specific file
        filepath = sys.argv[1]
        verify_episode_file(filepath)
    else:
        print("Usage: python verify_format_compatibility.py <episode.pkl>")
        print("\nOr import and use verify_episode_file(path) in your code")
